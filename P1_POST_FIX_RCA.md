# P1 Post-Fix Validation RCA - Deep Analysis

**Date**: October 26, 2025  
**RCA Directory**: `logs/remote/rca-20251026-185051/`  
**Status**: ğŸ”´ **FIXES FAILED - ROOT CAUSES IDENTIFIED**

---

## Executive Summary

Both P1 fixes **FAILED** in validation testing:
1. ğŸ”´ **Deepgram latency**: Still 5-6 seconds (no improvement)
2. ğŸ”´ **OpenAI clipping**: Still occurs + audio accumulation bug

**Root Causes Identified**:
- Deepgram latency is **NOT** from `idle_cutoff_ms` - it's from **Deepgram Voice Agent API taking 3-4s to finalize STT**
- OpenAI used **WRONG PROFILE** (`telephony_ulaw_8k` with 800ms instead of `openai_realtime_24k` with 0ms)
- OpenAI audio **accumulates** because streaming playback manager gets starved (-52% drift)

---

## Test Calls Summary

### Call 1: Deepgram (1761504353.2179)
- **Start**: 2025-10-26 18:46:00 UTC
- **Duration**: ~43 seconds
- **Profile Used**: âœ… `telephony_responsive` (idle_cutoff_ms: 600) - CORRECT
- **Audio Quality**: SNR 66.8 dB âœ…
- **Latency**: ğŸ”´ **STILL 5-6 SECONDS** (no improvement)

### Call 2: OpenAI Realtime (1761504398.2183)
- **Start**: 2025-10-26 18:46:47 UTC
- **Duration**: ~95 seconds
- **Profile Used**: âŒ `telephony_ulaw_8k` (idle_cutoff_ms: 800) - **WRONG PROFILE!**
- **Audio Quality**: SNR 66.7 dB âœ…
- **Clipping**: ğŸ”´ **YES - Audio accumulated and played at end**

---

## Issue #1: Deepgram Latency Analysis ğŸ”

### Event Timeline (Call 1761504353.2179)

```
+0.00s  | 18:46:00.954 | ğŸ¤– Agent greeting: "Hello, how can I help you today?"
+4.49s  | 18:46:05.440 | ğŸ¤ User started speaking
                       |    â†“ [USER SPEAKING...]
+8.16s  | 18:46:09.119 | ğŸ“ STT detected: "Hello. What is your name?"
                       |    â±ï¸ STT DELAY: 3.67 seconds (from start speaking to text)
+8.93s  | 18:46:09.881 | ğŸ¤– Agent responds: "I don't have a personal name."
                       |    â±ï¸ RESPONSE DELAY: 0.77s (from text to response)

TOTAL LATENCY: 4.44s (from user stop speaking to agent response)
```

### Latency Breakdown

| Phase | Duration | % of Total |
|-------|----------|------------|
| **User Speaking** | ~1.0-1.5s | N/A (variable) |
| **Deepgram STT Finalization** | **3.67s** | **ğŸ”´ 82%** |
| **LLM + TTS Processing** | 0.77s | 18% |
| **Total (STT â†’ Response)** | 4.44s | 100% |

### Root Cause: Deepgram Voice Agent API Latency

**The `idle_cutoff_ms: 600` fix had NO EFFECT because the bottleneck is NOT in VAD finalization.**

The latency breakdown shows:
1. âœ… VAD correctly detected user started speaking at +4.49s
2. ğŸ”´ **Deepgram took 3.67 seconds** to finalize the STT and return text
3. âœ… LLM + TTS responded quickly (0.77s)

**Deepgram Voice Agent API Behavior**:
- Uses its own internal VAD and conversation intelligence
- Waits for "natural turn-taking" cues before finalizing
- Cannot be controlled via `idle_cutoff_ms` (that's local VAD only)
- The 3-4 second delay is **built into the Deepgram service**

### Why idle_cutoff_ms Didn't Help

```
LOCAL VAD (idle_cutoff_ms: 600)
  â†“
Detects silence at 600ms
  â†“
BUT audio still flows to Deepgram...
  â†“
DEEPGRAM VAD (internal, ~3-4s)
  â†“
Deepgram decides when to finalize
  â†“
Returns transcript
```

**The local `idle_cutoff_ms` only affects when WE stop listening, but Deepgram Voice Agent API has its own finalization logic that takes 3-4 seconds regardless.**

---

## Issue #2: OpenAI Clipping & Accumulation Analysis ğŸ”

### Critical Finding: WRONG PROFILE USED

```json
{
  "profile": "telephony_ulaw_8k",
  "provider": "openai_realtime",
  "idle_cutoff_ms": 800,  // â† WRONG! Should be 0
  "event": "Resolved audio profile for call"
}
```

**The OpenAI call used `telephony_ulaw_8k` instead of `openai_realtime_24k`!**

This means:
- `idle_cutoff_ms: 800` was active (should be 0)
- Our fix was **never applied** to this call

### Event Timeline (Call 1761504398.2183)

```
+0.00s  | 18:46:51.163 | ğŸ¤– OpenAI response created (greeting)
+0.03s  | 18:46:51.190 | ğŸµ Streaming playback started
+0.15s  | 18:46:51.317 | ğŸµ First frame sent
+5.03s  | 18:46:56.196 | ğŸµ KEEPALIVE (no audio!)
+6.37s  | 18:46:57.529 | ğŸ¤– OpenAI response created (2nd response)
+8.42s  | 18:46:59.583 | Ended segment gating
+10.03s | 18:47:01.197 | ğŸµ KEEPALIVE
+17.01s | 18:47:08.173 | ğŸ¤– OpenAI response created (3rd response)
+28.23s | 18:47:19.395 | ğŸ¤– OpenAI response created (4th response)
+29.65s | 18:47:20.812 | ğŸ¤– OpenAI response created (5th response)
+44.86s | 18:47:36.026 | ğŸ›ï¸ STREAMING TUNING SUMMARY
         | - bytes_sent: 344,320 bytes
         | - effective_seconds: 21.52s
         | - wall_seconds: 44.836s
         | - drift: -52% (playback 52% slower than provider!)
```

### What Happened: Audio Accumulation Bug

**Streaming Playback Manager Behavior**:
1. Started streaming greeting at +0.03s
2. Sent first frame at +0.15s
3. **Provider stopped sending audio** (or audio was gated)
4. Streaming manager sent KEEPALIVES (silence) for 44 seconds
5. When call ended, **all accumulated audio played in a burst**

**Drift Analysis**:
- **Effective audio**: 21.52 seconds
- **Wall time**: 44.86 seconds
- **Drift**: -52% (playback was 52% slower!)

This means:
- Provider sent ~21.5 seconds of audio
- But it took 44.8 seconds to "play" it
- **22+ seconds were spent sending silence/keepalives**
- Audio accumulated and played at the end

### Root Cause: Audio Gating vs Streaming Manager Conflict

From logs:
```
ğŸšª Audio gate CLOSED (agent speaking) - 94 times
ğŸš« Audio NOT forwarded (gating active) - 94 times
ğŸ“¦ Buffering audio (low VAD confidence - likely echo) - 94 times
```

**The audio gating system blocked 94 audio chunks!**

**Sequence of Events**:
1. OpenAI starts sending audio (response)
2. Audio gating detects "agent speaking" â†’ closes gate
3. Provider audio is buffered (not forwarded to caller)
4. Streaming manager doesn't receive audio â†’ sends keepalives
5. OpenAI finishes response â†’ audio gate opens
6. Buffered audio finally released
7. But streaming manager already moved on â†’ audio accumulates
8. At call end, all accumulated audio plays in burst

---

## Why The Fixes Didn't Work

### Fix #1: Reduce idle_cutoff_ms for Deepgram âŒ

**Expected**: Reduce latency from 5-6s to 2.5-3.5s  
**Result**: No improvement - still 5-6s  
**Reason**: Latency is in **Deepgram API**, not local VAD

### Fix #2: Disable idle_cutoff_ms for OpenAI âŒ

**Expected**: No clipping, complete responses  
**Result**: Still clipped and accumulated  
**Reason #1**: **Wrong profile used** (`telephony_ulaw_8k` not `openai_realtime_24k`)  
**Reason #2**: **Audio gating conflict** blocks audio from streaming manager

---

## Real Root Causes

### Deepgram Latency

ğŸ”´ **Root Cause**: **Deepgram Voice Agent API's built-in conversation intelligence**

The Deepgram Voice Agent API:
- Has its own internal VAD
- Uses conversation intelligence to detect natural turn-taking
- Waits 3-4 seconds after silence before finalizing
- **Cannot be configured or overridden** via client settings

**This is a SERVICE LIMITATION, not a configuration issue.**

### OpenAI Audio Accumulation

ğŸ”´ **Root Cause #1**: **Profile Selection Bug**

Dialplan doesn't set `AI_AUDIO_PROFILE=openai_realtime_24k`, so call used default profile with wrong settings.

ğŸ”´ **Root Cause #2**: **Audio Gating vs Streaming Manager Race Condition**

The audio gating system (for echo prevention) and streaming playback manager are fighting:
1. Provider sends audio â†’ gating buffers it (thinks it's echo)
2. Streaming manager doesn't get audio â†’ sends keepalives
3. Gating releases audio later â†’ but stream is already "idle"
4. Audio accumulates in buffer
5. At call end, buffer flushes â†’ all audio plays at once

---

## Solutions

### Solution #1: Deepgram Latency (ACCEPT or SWITCH)

**Option A: Accept the Latency** (Recommended)

Deepgram Voice Agent API is **designed** for natural conversation, not speed:
- 3-4 second latency is intentional
- Ensures high-quality turn-taking
- Prevents interrupting slow speakers

**If low latency is required**, use:
- **Deepgram STT (non-agent mode)** with custom VAD tuning
- **OpenAI Realtime** (faster STT, <1s latency)
- **Local STT** (TinyLlama, <500ms latency)

**Option B: Switch to Deepgram STT-only Mode**

Use `deepgram_stt` adapter instead of `deepgram` Voice Agent:
```yaml
pipelines:
  fast_deepgram:
    stt: deepgram_stt  # â† Direct STT, not Voice Agent
    llm: openai_llm
    tts: deepgram_tts
```

Configure with aggressive VAD:
```yaml
deepgram_stt:
  vad_events: true
  endpointing: 300  # â† 300ms silence = finalize
```

**Expected latency**: 300ms STT + 500ms LLM + 300ms TTS = **~1.1s total** âœ…

---

### Solution #2: OpenAI Audio Accumulation (FIX REQUIRED)

**Fix #1: Set Correct Profile in Dialplan**

```asterisk
[from-ai-agent-openai]
exten => s,1,Set(AI_PROVIDER=openai_realtime)
 same => n,Set(AI_AUDIO_PROFILE=openai_realtime_24k)  # â† ADD THIS LINE
 same => n,Stasis(asterisk-ai-voice-agent)
 same => n,Hangup()
```

**Fix #2: Disable Audio Gating for OpenAI Realtime**

OpenAI Realtime has **built-in server-side echo cancellation**. Local audio gating interferes with it.

**Option A: Disable gating for OpenAI provider** (config)

```yaml
# config/ai-agent.yaml
providers:
  openai_realtime:
    audio_gating_enabled: false  # â† ADD THIS
```

**Option B: Fix gating logic to not block provider audio**

Currently, audio gating blocks:
1. Inbound audio (caller â†’ provider) âœ… Correct
2. **Outbound audio (provider â†’ caller)** âŒ **WRONG!**

Provider audio should **NEVER** be gated. Only caller audio should be gated during agent playback.

**Code fix required** in `src/core/session_store.py` or `src/engine.py`:
```python
# CURRENT (WRONG):
if audio_gate_closed:
    buffer_audio()  # Blocks EVERYTHING

# SHOULD BE:
if audio_gate_closed and direction == "inbound":
    buffer_audio()  # Only block caller audio
elif direction == "outbound":
    forward_audio()  # Always forward provider audio
```

---

## Detailed Metrics

### Call 1 (Deepgram): 1761504353.2179

| Metric | Value | Status |
|--------|-------|--------|
| **Duration** | 43.2s | âœ… |
| **SNR** | 66.8 dB | âœ… Excellent |
| **Profile** | telephony_responsive | âœ… Correct |
| **idle_cutoff_ms** | 600 | âœ… Applied |
| **STT Latency** | 3.67s | ğŸ”´ High (Deepgram API) |
| **LLM+TTS Latency** | 0.77s | âœ… Fast |
| **Total Latency** | 4.44s | ğŸ”´ Above target (3.5s) |

### Call 2 (OpenAI): 1761504398.2183

| Metric | Value | Status |
|--------|-------|--------|
| **Duration** | 95.3s | âœ… |
| **SNR** | 66.7 dB | âœ… Excellent |
| **Profile** | telephony_ulaw_8k | âŒ Wrong! |
| **idle_cutoff_ms** | 800 | âŒ Should be 0 |
| **Bytes Sent** | 344,320 bytes (21.52s) | âš ï¸ |
| **Wall Time** | 44.86s | ğŸ”´ |
| **Drift** | -52% | ğŸ”´ Severe |
| **Audio Gate Blocks** | 94 times | ğŸ”´ Critical |
| **Clipping** | YES | ğŸ”´ |
| **Accumulation** | YES | ğŸ”´ |

---

## Recommended Actions

### Immediate (Critical)

1. **Update OpenAI dialplan** to use `openai_realtime_24k` profile
   ```asterisk
   Set(AI_AUDIO_PROFILE=openai_realtime_24k)
   ```

2. **Disable audio gating for OpenAI Realtime**
   ```yaml
   providers:
     openai_realtime:
       audio_gating_enabled: false
   ```

3. **Re-test OpenAI** with correct profile + disabled gating

### Short-Term (High Priority)

4. **Fix audio gating logic** to never block provider â†’ caller audio

5. **Document Deepgram latency** as known limitation in docs

6. **Add profile validation** to warn if wrong profile used for provider

### Long-Term (Medium Priority)

7. **Implement Deepgram STT-only mode** for low-latency use cases

8. **Add streaming health checks** to detect drift > 30% and warn/recover

9. **Add profile recommendations** based on provider in config validation

---

## Testing Plan (Re-validation)

### Test 1: OpenAI with Correct Profile

**Setup**:
```asterisk
Set(AI_PROVIDER=openai_realtime)
Set(AI_AUDIO_PROFILE=openai_realtime_24k)  # â† Key change
```

**Config**:
```yaml
providers:
  openai_realtime:
    audio_gating_enabled: false  # â† Key change
```

**Expected Results**:
- âœ… No clipping
- âœ… Complete responses
- âœ… No accumulation
- âœ… Drift < 10%

### Test 2: Deepgram STT-only (Low Latency)

**Setup**:
```yaml
pipelines:
  fast_deepgram:
    stt: deepgram_stt
    llm: openai_llm
    tts: deepgram_tts
```

**Expected Results**:
- âœ… Latency < 2s
- âœ… Fast turn-taking

---

## Conclusion

**P1 Fixes Status**: ğŸ”´ **FAILED** (but root causes now understood)

**Key Findings**:
1. Deepgram latency is a **SERVICE LIMITATION**, not fixable via config
2. OpenAI issue was **WRONG PROFILE** + **AUDIO GATING CONFLICT**
3. Both issues have solutions, but require different approaches

**Next Steps**:
1. Fix OpenAI profile selection + disable gating
2. Document Deepgram latency limitation
3. Consider Deepgram STT-only for low-latency scenarios
4. Fix audio gating to not block provider audio

**Estimated Time to Fix**: 1-2 hours

---

**RCA Status**: âœ… **COMPLETE - ROOT CAUSES IDENTIFIED**  
**Priority**: ğŸ”´ **CRITICAL** (OpenAI unusable, Deepgram sub-optimal)
